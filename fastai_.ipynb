{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICJKvowhHbTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import torch.nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b_L0PIHOfOE",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FzPptYpOoI1",
        "colab_type": "text"
      },
      "source": [
        "try to shuffel your data in training set. Random sampling\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3YCQYoePAGm",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaHHDob5OelT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "# valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_fWuTUVvFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class DataBunch():\n",
        "    def __init__(self, train_dl, valid_dl, c=None):\n",
        "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
        "        \n",
        "    @property\n",
        "    def train_ds(self): return self.train_dl.dataset\n",
        "        \n",
        "    @property\n",
        "    def valid_ds(self): return self.valid_dl.dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM9XqxSCTt8X",
        "colab_type": "text"
      },
      "source": [
        "#Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y84mJDbfTs8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Callback():\n",
        "    _order = 0\n",
        "    \n",
        "    def set_runner(self, run): self.run = run\n",
        "    def __getattr__(self, k): return getattr(self.run, k)\n",
        "\n",
        "    def begin_fit(self):\n",
        "        return True\n",
        "    def after_fit(self): return True\n",
        "    def begin_epoch(self):\n",
        "        return True\n",
        "    def begin_validate(self): return True\n",
        "    def after_epoch(self): return True\n",
        "    def begin_batch(self):\n",
        "        return True\n",
        "    def after_loss(self):\n",
        "        return True\n",
        "    def after_backward(self): return True\n",
        "    def after_step(self): return True\n",
        "    def after_pred(self): return True\n",
        "    def after_cancel_batch(self): return True\n",
        "    def after_cancel_epoch(self): return True\n",
        "    \n",
        "    def __call__(self, cb_name):\n",
        "        f = getattr(self, cb_name, None)\n",
        "        if f and f(): return True\n",
        "        return False\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt8OguYXl87Z",
        "colab_type": "text"
      },
      "source": [
        "**This is a must callback**\n",
        "calls model.train() and model.eval() at appropriate times and sets other necessary values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctuvl04Ql8Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainEvalCallback(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.run.n_epochs=0.\n",
        "        self.run.n_iter=0\n",
        "    \n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.run.n_epochs += 1./self.iters\n",
        "        self.run.n_iter   += 1\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.run.n_epochs=self.epoch\n",
        "        self.model.train()\n",
        "        self.run.in_train=True\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.model.eval()\n",
        "        self.run.in_train=False\n",
        "\n",
        "class CancelTrainException(Exception): pass\n",
        "class CancelEpochException(Exception): pass\n",
        "class CancelBatchException(Exception): pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_2EgLcDcXO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AvgStatsCallback(Callback):\n",
        "    def __init__(self, metrics):\n",
        "        self.metrics = metrics\n",
        "        self.train_stats,self.valid_stats = AvgStats( [],True),AvgStats(metrics,False)\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.train_stats.reset()\n",
        "        self.valid_stats.reset()\n",
        "        \n",
        "    def after_loss(self):\n",
        "        stats = self.train_stats if self.in_train else self.valid_stats\n",
        "        with torch.no_grad(): stats.accumulate(self.run)\n",
        "    \n",
        "    def after_epoch(self):\n",
        "        mtrs = \"\"\n",
        "        for metric in self.metrics:\n",
        "            mtrs = \"%14s\"%metric.__name__\n",
        "        if self.epoch == 0: print(\"%14s\"%\"train loss\"+\"%14s\"%\"valid loss\"+ mtrs)\n",
        "        print(str(self.train_stats)+ str(self.valid_stats))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NIoN1Vkj3OE",
        "colab_type": "text"
      },
      "source": [
        " the Recorder to save track of the loss and our scheduled learning rate, and a ParamScheduler that can schedule any hyperparameter as long as it's registered in the state_dict of the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cERB6_RGjuqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recorder(Callback):\n",
        "    def begin_fit(self): self.lrs, self.losses = [], []\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return \n",
        "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
        "        self.losses.append(self.loss.detach().cpu())\n",
        "\n",
        "    def plot_lr(self): plt.plot(self.lrs)\n",
        "    def plot_loss(self): plt.plot(self.losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C2745VClILL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParamSchheduler(Callback):\n",
        "  _order = 1\n",
        "  def __init__(self, pname, sched_func): self.pname, self.sched_func = pname, sched_func\n",
        "    \n",
        "  def set_param(self):\n",
        "    for pg in self.opt.param_groups:\n",
        "      pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
        "      \n",
        "  def begin_batch(self):\n",
        "    if self.in_train: self.set_param()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-klmirFtLQV",
        "colab_type": "text"
      },
      "source": [
        "**scheduler functions to be added**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDs4BReStEWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CudaCallback(Callback):\n",
        "    def begin_fit(self): self.model.cuda()\n",
        "    def begin_batch(self): self.run.xb,self.run.yb = self.xb.cuda(),self.yb.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0QZRQR6NNU0",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAkyMsapN998",
        "colab_type": "text"
      },
      "source": [
        "a basic optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_rIoCeZN8AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class Optimizer():\n",
        "  \n",
        "#   def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "    \n",
        "#   def step(self):\n",
        "#     with torch.no_grad():\n",
        "#       for p in self.params: p -= p.grad*lr\n",
        "        \n",
        "#   def zero_grad(self):\n",
        "#     for p in self.params: p.grad.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU5K4ubtNM20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Learner():\n",
        "    def __init__(self, model, opt, loss_func, data):\n",
        "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He5rJcDQteSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Runner():\n",
        "    def __init__(self, callbacks = None):\n",
        "        self.cbs = [TrainEvalCallback()] + callbacks\n",
        "        self.stop = False\n",
        "\n",
        "    @property\n",
        "    def opt(self):\n",
        "        return self.learn.opt\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.learn.model\n",
        "    @property\n",
        "    def loss_func(self):\n",
        "        return self.learn.loss_func\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self.learn.data\n",
        "\n",
        "    def one_batch(self, xb, yb):\n",
        "        try:\n",
        "            self.xb, self.yb = xb, yb\n",
        "            self('begin_batch')\n",
        "            self.pred = self.model(self.xb)\n",
        "            self('after_pred')\n",
        "            self.loss = self.loss_func(self.pred, self.yb)\n",
        "            self('after_loss')\n",
        "            if not self.in_train: return\n",
        "            self.loss.backward()\n",
        "            self('after_backward')\n",
        "            self.opt.step()\n",
        "            self('after_step')\n",
        "            self.opt.zero_grad()\n",
        "        except CancelBatchException: self('')\n",
        "        finally: self('after_batch')\n",
        "\n",
        "    def all_batches(self, dl):\n",
        "        self.iters = len(dl)\n",
        "        try:\n",
        "            for xb, yb in dl: self.one_batch(xb, yb)\n",
        "        except CancelEpochException: self('after_cancel_epoch')\n",
        "\n",
        "    def fit(self, epochs, learn):\n",
        "        self.epochs, self.learn, self.loss = epochs, learn, torch.tensor(0.)\n",
        "\n",
        "        try:\n",
        "            for cb in self.cbs: cb.set_runner(self)\n",
        "            self('begin_fit')\n",
        "            self\n",
        "            for epoch in range(epochs):\n",
        "                self.epoch = epoch\n",
        "                self('begin_epoch') \n",
        "                self.all_batches(self.data.train_dl)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    self('begin_validate')\n",
        "                    self.all_batches(self.data.valid_dl)\n",
        "                self('after_epoch')\n",
        "\n",
        "        except CancelTrainException: self('after_cancel_train')\n",
        "        finally:\n",
        "            self('after_fit')\n",
        "            self.learn = None\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        res = False\n",
        "        for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) and res\n",
        "        return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enmzeBwhNCVG",
        "colab_type": "text"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk-4w_85NB7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb): return (torch.argmax(out,dim=1)==yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19VGuXqGWogZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AvgStats():\n",
        "  def __init__(self, metrics, in_train): self.metrics, self.in_train = metrics, in_train\n",
        "    \n",
        "  def reset(self):\n",
        "    self.tot_loss, self.count = 0., 0\n",
        "    self.tot_mets = [0.]*len(self.metrics)\n",
        "    \n",
        "  @property\n",
        "  def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
        "  \n",
        "  @property\n",
        "  def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
        "\n",
        "  @property\n",
        "  def printAvgStats(self):\n",
        "      result = ''\n",
        "      for idx,stat in enumerate(self.avg_stats):\n",
        "          if idx==0 :\n",
        "              result += \"%14s\"%('%.6f'%stat)\n",
        "          else:\n",
        "\n",
        "              result += \"%14s\"%('%.6f'%stat)\n",
        "      return result\n",
        "  \n",
        "  def __repr__(self):\n",
        "    if not self.count: return \"\"\n",
        "    return f\"{self.printAvgStats}\"\n",
        "  \n",
        "  def accumulate(self, run):\n",
        "    bn = run.xb.shape[0]\n",
        "    self.tot_loss += run.loss*bn\n",
        "    self.count += bn\n",
        "    for i,m in enumerate(self.metrics):\n",
        "      self.tot_mets[i] += m(run.pred, run.yb)*bn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBdci_oDZL-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}